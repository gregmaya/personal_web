[
  {
    "objectID": "work/data_viz/end_ch_poverty.html",
    "href": "work/data_viz/end_ch_poverty.html",
    "title": "End Child Poverty",
    "section": "",
    "text": "a short description of my impact and involvement in A19 GxR reports and overall pipeline.",
    "crumbs": [
      "About",
      "Data Visualisation",
      "End Child Poverty"
    ]
  },
  {
    "objectID": "work/data_viz/index_data.html",
    "href": "work/data_viz/index_data.html",
    "title": "Data Visualisation",
    "section": "",
    "text": "a short description of my take and the reason I do this."
  },
  {
    "objectID": "work/index_work.html",
    "href": "work/index_work.html",
    "title": "Works",
    "section": "",
    "text": "A small selection of projects that I have had the pleasure to work on. Most of these projects are collaborations with different companies and designers, all of which are credited in the description of each project.\nProjects are classified into categories to make the exploratory process simpler. However, depending on the project the boundaries between categories can be fuzzy."
  },
  {
    "objectID": "work/archi/bru.html",
    "href": "work/archi/bru.html",
    "title": "Building Research Unit (BRU)",
    "section": "",
    "text": "develop publishable content",
    "crumbs": [
      "About",
      "Architecture & Strategy",
      "Building Research Unit"
    ]
  },
  {
    "objectID": "work/others/talks.html",
    "href": "work/others/talks.html",
    "title": "Talks",
    "section": "",
    "text": "FADU - ARG\nUniversidad Nacional del Litoral\nJune 2023 | Spanish | Remote\nFacultad de Arquitectura, Diseño y Urbanismo\n\n\n\n\nUNIANDES - COL\nUniversidad de los Andes\nNovember 2018 | Spanish | On-site\nFacultad de Arquitectura y Diseño",
    "crumbs": [
      "About",
      "Others",
      "Talks"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Greg Maya",
    "section": "",
    "text": "I am Gregorio Maya, City Science Coordinator at the Norman Foster Institute and a freelance consultant for various NGOs. Trained as an architect with a Summa Cum Laude degree, I have pivoted from traditional design to focus on the data-driven aspects of urban environments. My passion lies in analyzing spatial configurations to understand behavioral dynamics within built spaces, often applying principles of behavioral economics to enhance both client engagements and design outcomes.\nIn my role, I co-lecture in Urban Analytics and lead the technical development of sustainability tools for cities. As a Tableau-certified analyst proficient in open-source tools like Python, QGIS, and PostgreSQL, I contribute to creating sustainable urban solutions. My work involves mentoring the next generation of urban analysts, leading digital projects that integrate data science with urban design, and consulting for NGOs, providing insights that promote sustainable and effective urban development.\nI maintain active academic ties not only with my alma maters, The Bartlett-UCL (UK) and Universidad de los Andes (COL), but also by collaborating closely with professors at UCA Canterbury (UK) and Universidad Nacional del Litoral (ARG)."
  },
  {
    "objectID": "index.html#bio",
    "href": "index.html#bio",
    "title": "Greg Maya",
    "section": "",
    "text": "I am Gregorio Maya, City Science Coordinator at the Norman Foster Institute and a freelance consultant for various NGOs. Trained as an architect with a Summa Cum Laude degree, I have pivoted from traditional design to focus on the data-driven aspects of urban environments. My passion lies in analyzing spatial configurations to understand behavioral dynamics within built spaces, often applying principles of behavioral economics to enhance both client engagements and design outcomes.\nIn my role, I co-lecture in Urban Analytics and lead the technical development of sustainability tools for cities. As a Tableau-certified analyst proficient in open-source tools like Python, QGIS, and PostgreSQL, I contribute to creating sustainable urban solutions. My work involves mentoring the next generation of urban analysts, leading digital projects that integrate data science with urban design, and consulting for NGOs, providing insights that promote sustainable and effective urban development.\nI maintain active academic ties not only with my alma maters, The Bartlett-UCL (UK) and Universidad de los Andes (COL), but also by collaborating closely with professors at UCA Canterbury (UK) and Universidad Nacional del Litoral (ARG)."
  },
  {
    "objectID": "geo_env/lib/python3.10/site-packages/httpx-0.27.0.dist-info/licenses/LICENSE.html",
    "href": "geo_env/lib/python3.10/site-packages/httpx-0.27.0.dist-info/licenses/LICENSE.html",
    "title": "Greg Maya",
    "section": "",
    "text": "Copyright © 2019, Encode OSS Ltd. All rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."
  },
  {
    "objectID": "geo_env/lib/python3.10/site-packages/numpy/random/LICENSE.html",
    "href": "geo_env/lib/python3.10/site-packages/numpy/random/LICENSE.html",
    "title": "NCSA Open Source License",
    "section": "",
    "text": "This software is dual-licensed under the The University of Illinois/NCSA Open Source License (NCSA) and The 3-Clause BSD License\n\nNCSA Open Source License\nCopyright (c) 2019 Kevin Sheppard. All rights reserved.\nDeveloped by: Kevin Sheppard (kevin.sheppard@economics.ox.ac.uk, kevin.k.sheppard@gmail.com) http://www.kevinsheppard.com\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal with the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimers.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimers in the documentation and/or other materials provided with the distribution.\nNeither the names of Kevin Sheppard, nor the names of any contributors may be used to endorse or promote products derived from this Software without specific prior written permission.\nTHE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS WITH THE SOFTWARE.\n\n\n3-Clause BSD License\nCopyright (c) 2019 Kevin Sheppard. All rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n\nComponents\nMany parts of this module have been derived from original sources, often the algorithm’s designer. Component licenses are located with the component code."
  },
  {
    "objectID": "geo_env/lib/python3.10/site-packages/matplotlib/backends/web_backend/nbagg_uat.html",
    "href": "geo_env/lib/python3.10/site-packages/matplotlib/backends/web_backend/nbagg_uat.html",
    "title": "UAT for NbAgg backend.",
    "section": "",
    "text": "from imp import reload\nThe first line simply reloads matplotlib, uses the nbagg backend and then reloads the backend, just to ensure we have the latest modification to the backend code. Note: The underlying JavaScript will not be updated by this process, so a refresh of the browser after clearing the output and saving is necessary to clear everything fully.\nimport matplotlib\nreload(matplotlib)\n\nmatplotlib.use('nbagg')\n\nimport matplotlib.backends.backend_nbagg\nreload(matplotlib.backends.backend_nbagg)"
  },
  {
    "objectID": "geo_env/lib/python3.10/site-packages/matplotlib/backends/web_backend/nbagg_uat.html#uat-13---animation",
    "href": "geo_env/lib/python3.10/site-packages/matplotlib/backends/web_backend/nbagg_uat.html#uat-13---animation",
    "title": "UAT for NbAgg backend.",
    "section": "UAT 13 - Animation",
    "text": "UAT 13 - Animation\nThe following should generate an animated line:\n\nimport matplotlib.animation as animation\nimport numpy as np\n\nfig, ax = plt.subplots()\n\nx = np.arange(0, 2*np.pi, 0.01)        # x-array\nline, = ax.plot(x, np.sin(x))\n\ndef animate(i):\n    line.set_ydata(np.sin(x+i/10.0))  # update the data\n    return line,\n\n#Init only required for blitting to give a clean slate.\ndef init():\n    line.set_ydata(np.ma.array(x, mask=True))\n    return line,\n\nani = animation.FuncAnimation(fig, animate, np.arange(1, 200), init_func=init,\n                              interval=100., blit=True)\nplt.show()\n\n\nUAT 14 - Keyboard shortcuts in IPython after close of figure\nAfter closing the previous figure (with the close button above the figure) the IPython keyboard shortcuts should still function.\n\n\nUAT 15 - Figure face colours\nThe nbagg honours all colours apart from that of the figure.patch. The two plots below should produce a figure with a red background. There should be no yellow figure.\n\nimport matplotlib\nmatplotlib.rcParams.update({'figure.facecolor': 'red',\n                            'savefig.facecolor': 'yellow'})\nplt.figure()\nplt.plot([3, 2, 1])\n\nplt.show()\n\n\n\nUAT 16 - Events\nPressing any keyboard key or mouse button (or scrolling) should cycle the line while the figure has focus. The figure should have focus by default when it is created and re-gain it by clicking on the canvas. Clicking anywhere outside of the figure should release focus, but moving the mouse out of the figure should not release focus.\n\nimport itertools\nfig, ax = plt.subplots()\nx = np.linspace(0,10,10000)\ny = np.sin(x)\nln, = ax.plot(x,y)\nevt = []\ncolors = iter(itertools.cycle(['r', 'g', 'b', 'k', 'c']))\ndef on_event(event):\n    if event.name.startswith('key'):\n        fig.suptitle('%s: %s' % (event.name, event.key))\n    elif event.name == 'scroll_event':\n        fig.suptitle('%s: %s' % (event.name, event.step))\n    else:\n        fig.suptitle('%s: %s' % (event.name, event.button))\n    evt.append(event)\n    ln.set_color(next(colors))\n    fig.canvas.draw()\n    fig.canvas.draw_idle()\n\nfig.canvas.mpl_connect('button_press_event', on_event)\nfig.canvas.mpl_connect('button_release_event', on_event)\nfig.canvas.mpl_connect('scroll_event', on_event)\nfig.canvas.mpl_connect('key_press_event', on_event)\nfig.canvas.mpl_connect('key_release_event', on_event)\n\nplt.show()\n\n\n\nUAT 17 - Timers\nSingle-shot timers follow a completely different code path in the nbagg backend than regular timers (such as those used in the animation example above.) The next set of tests ensures that both “regular” and “single-shot” timers work properly.\nThe following should show a simple clock that updates twice a second:\n\nimport time\n\nfig, ax = plt.subplots()\ntext = ax.text(0.5, 0.5, '', ha='center')\n\ndef update(text):\n    text.set(text=time.ctime())\n    text.axes.figure.canvas.draw()\n    \ntimer = fig.canvas.new_timer(500, [(update, [text], {})])\ntimer.start()\nplt.show()\n\nHowever, the following should only update once and then stop:\n\nfig, ax = plt.subplots()\ntext = ax.text(0.5, 0.5, '', ha='center') \ntimer = fig.canvas.new_timer(500, [(update, [text], {})])\n\ntimer.single_shot = True\ntimer.start()\n\nplt.show()\n\nAnd the next two examples should never show any visible text at all:\n\nfig, ax = plt.subplots()\ntext = ax.text(0.5, 0.5, '', ha='center')\ntimer = fig.canvas.new_timer(500, [(update, [text], {})])\n\ntimer.start()\ntimer.stop()\n\nplt.show()\n\n\nfig, ax = plt.subplots()\ntext = ax.text(0.5, 0.5, '', ha='center')\ntimer = fig.canvas.new_timer(500, [(update, [text], {})])\n\ntimer.single_shot = True\ntimer.start()\ntimer.stop()\n\nplt.show()\n\n\n\nUAT 18 - stopping figure when removed from DOM\nWhen the div that contains from the figure is removed from the DOM the figure should shut down it’s comm, and if the python-side figure has no more active comms, it should destroy the figure. Repeatedly running the cell below should always have the same figure number\n\nfig, ax = plt.subplots()\nax.plot(range(5))\nplt.show()\n\nRunning the cell below will re-show the figure. After this, re-running the cell above should result in a new figure number.\n\nfig.canvas.manager.reshow()\n\n\n\nUAT 19 - Blitting\nClicking on the figure should plot a green horizontal line moving up the axes.\n\nimport itertools\n\ncnt = itertools.count()\nbg = None\n\ndef onclick_handle(event):\n    \"\"\"Should draw elevating green line on each mouse click\"\"\"\n    global bg\n    if bg is None:\n        bg = ax.figure.canvas.copy_from_bbox(ax.bbox) \n    ax.figure.canvas.restore_region(bg)\n\n    cur_y = (next(cnt) % 10) * 0.1\n    ln.set_ydata([cur_y, cur_y])\n    ax.draw_artist(ln)\n    ax.figure.canvas.blit(ax.bbox)\n\nfig, ax = plt.subplots()\nax.plot([0, 1], [0, 1], 'r')\nln, = ax.plot([0, 1], [0, 0], 'g', animated=True)\nplt.show()\nax.figure.canvas.draw()\n\nax.figure.canvas.mpl_connect('button_press_event', onclick_handle)"
  },
  {
    "objectID": "geo_env/lib/python3.10/site-packages/QtPy-2.4.1.dist-info/AUTHORS.html",
    "href": "geo_env/lib/python3.10/site-packages/QtPy-2.4.1.dist-info/AUTHORS.html",
    "title": "Authors",
    "section": "",
    "text": "pyqode.qt: Colin Duquesnoy (@ColinDuquesnoy)\nspyderlib.qt: Pierre Raybaut (@PierreRaybaut)\nqt-helpers: Thomas Robitaille (@astrofrog)\n\n\n\n\n\nDaniel Althviz (@dalthviz)\nCarlos Cordoba (@ccordoba12)\nC.A.M. Gerlach (@CAM-Gerlach)\nSpyder Development Team (Spyder-IDE)\n\n\n\n\n\nThe QtPy Contributors"
  },
  {
    "objectID": "geo_env/lib/python3.10/site-packages/QtPy-2.4.1.dist-info/AUTHORS.html#original-authors",
    "href": "geo_env/lib/python3.10/site-packages/QtPy-2.4.1.dist-info/AUTHORS.html#original-authors",
    "title": "Authors",
    "section": "",
    "text": "pyqode.qt: Colin Duquesnoy (@ColinDuquesnoy)\nspyderlib.qt: Pierre Raybaut (@PierreRaybaut)\nqt-helpers: Thomas Robitaille (@astrofrog)"
  },
  {
    "objectID": "geo_env/lib/python3.10/site-packages/QtPy-2.4.1.dist-info/AUTHORS.html#current-maintainers",
    "href": "geo_env/lib/python3.10/site-packages/QtPy-2.4.1.dist-info/AUTHORS.html#current-maintainers",
    "title": "Authors",
    "section": "",
    "text": "Daniel Althviz (@dalthviz)\nCarlos Cordoba (@ccordoba12)\nC.A.M. Gerlach (@CAM-Gerlach)\nSpyder Development Team (Spyder-IDE)"
  },
  {
    "objectID": "geo_env/lib/python3.10/site-packages/QtPy-2.4.1.dist-info/AUTHORS.html#contributors",
    "href": "geo_env/lib/python3.10/site-packages/QtPy-2.4.1.dist-info/AUTHORS.html#contributors",
    "title": "Authors",
    "section": "",
    "text": "The QtPy Contributors"
  },
  {
    "objectID": "my_cv.html",
    "href": "my_cv.html",
    "title": "Curriculum Vitae",
    "section": "",
    "text": "Location-Based Problem Solving\ngregoriomaya@gmail.comPorfolio\n\nPassionate professional with 9+ years of experience delivering high-impact work in the built environment. Trained as an Architect, develop skills in strong internal and external relationships to facilitate the cooperative achievement of high-priority goals. Confident in my ability to thrive in a fast-paced environment where I leverage skills in lecturing, product development, data analysis, and research. Committed to lifelong learning and going the extra mile to facilitate continuous improvement for myself and my colleagues.\n\n\n\n\nSkills\n\n\nTableau (Certified)\nQGIS\nSQL (PostSQL)\nPython\nVsCode\n\n\n\nLanguages\n\n\nSpanish native\nEnglish biligual\nFrench professional\nPortuguese conversational\n\n\n\n\nExperience\n\n\nCity Science Coordinator\nNorman Foster Institute | Madrid June 2023 – Present\nAs part of the in-house staff of the Master in Sustainable Cities, my main responsabilities include the co-creation of the Urban Analytics lesson and the development of the City Pulse -a multi-user app for diagnosing sustanability targets.\n\nMaintining client relationships with 3 city administrations : Athens, Bilbao and San Marino. Consultancy model to deliver actionable projects.\nCo-creation of 16-week GIS course and subsequent lab support for 24 scholars. From Open source softwares (QGIS, PostGIS), through Python based notebooks to user friendly web-apps\n\n\n\nData Consultant\nFreelance, Multiple Clients | World 2021 – Present\nProviding data collection, pre-processing, exploratory analysis and modelling services to clients (Private and NGOs) in their R&D stages of developing data driven products. Projects include:\n\nArticle 19 Global Expression Report: internal transformation of a proprietary index report into a digital product that embraces modern data management and delivery. Currently with over 500K views in embeded website.\nAccesnture & JLR : daily database updates with 120+ country wide post-sales managers. Optimising pipelines for Tableau dashboards with dynamic views based on custom profiles; delivery to emails.\nACASA : asseses their current pipelines and to create a pipeline for a spatially-aware pricing index for faster response to clients and new business avenues. Reduced initial delivery times 7 fold (from weekly to less than 1hour)\n\n\n\nSpatial Intelligence Lead\nSENSE | London Nov 2018 – May 2022\nMain responsibilities included the translation of business goals into innovative metrics for clients. Create the unit of data analysis that delivers the business’s unique selling point -USP.\n\nInterpret and deliver domain expertise in the Architectural, Design, and Construction (AEC) industry to the internal technical team.\nCreate a pipeline of future feature developments based on sophisticated data modeling techniques.\n\n\n\nUrban Consultant\nSpace Syntax Lmtd | London Sept 2016 – Oct 2018\nAdvise and support of local authorities and large-scale private developers of the urban environments in London, China, and Kazakhstan.\n\nCreate models for assessing new layouts with measures of urban centrality and connectivity.\nRecreate internal GIS processes for faster and more accurate delivery of reports.\n\n\nEducation\n\nMSc Spatial Intelligence: Space Syntax  UCL - The Bartlett (UK) 2015 – 2016 Honours degree\nBachelor in Architecture  Universidad de los Andes (COL) 2008 – 2013 Summa Cum Laude Laureate\nSwiss Matura & Colombian High School Diploma  Colegio Helvetia de Bogota (COL) 2007\n\n\nCourses\n\n\nProduct Management  NOVA Madrid | 2023\n\n\n\nData Science GENERAL ASSEMBLY London | 2019\n\n\n\nPython 3 CODE ACADEMY London | 2018\n\n\n\nOthers\n\n\nMOMEPY collaborator Google Summer of Code contributor grant 2022\nR. Salmona Fellowship British Council research grant 2019\nFrequent lecturer: UNIANDES (COL) | UCA Canterbury (UK) | FADU - UNL (ARG)\n\n\n\n\nReferences\nAvailable upon request"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Location-Based Problem Solving",
    "section": "",
    "text": "Welcome to my website —a space where I share highlights from my work as well as reflect on the journey shaped by my daily efforts. As an ongoing project, this site serves both as a repository for my professional contributions and as a canvas for my evolving thoughts on how we interact with the spaces around us."
  },
  {
    "objectID": "about.html#mission",
    "href": "about.html#mission",
    "title": "Location-Based Problem Solving",
    "section": "Mission",
    "text": "Mission\nTo work across disciplines to surface the hidden properties of the built environment."
  },
  {
    "objectID": "about.html#vision",
    "href": "about.html#vision",
    "title": "Location-Based Problem Solving",
    "section": "Vision",
    "text": "Vision\nA built-environemnt industry that embraces the opportunities that lie in space to trigger positive social behaviours."
  },
  {
    "objectID": "geo_env/lib/python3.10/site-packages/idna-3.7.dist-info/LICENSE.html",
    "href": "geo_env/lib/python3.10/site-packages/idna-3.7.dist-info/LICENSE.html",
    "title": "Greg Maya",
    "section": "",
    "text": "BSD 3-Clause License\nCopyright (c) 2013-2024, Kim Davies and contributors. All rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."
  },
  {
    "objectID": "geo_env/lib/python3.10/site-packages/httpcore-1.0.5.dist-info/licenses/LICENSE.html",
    "href": "geo_env/lib/python3.10/site-packages/httpcore-1.0.5.dist-info/licenses/LICENSE.html",
    "title": "Greg Maya",
    "section": "",
    "text": "Copyright © 2020, Encode OSS Ltd. All rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."
  },
  {
    "objectID": "geo_env/lib/python3.10/site-packages/libpysal/cg/tests/fast_point_in_polygon_algorithm.html",
    "href": "geo_env/lib/python3.10/site-packages/libpysal/cg/tests/fast_point_in_polygon_algorithm.html",
    "title": "Fast Point in Polygon Testing Method",
    "section": "",
    "text": "Author: Hu Shao shaohutiger@gmail.com\n\n\n\n\nBegin test without quad-tree-structure Test without quad-tree-structure finished, time used = 23.204s\nBegin test with quad-tree-structure Test with quad-tree-structure finished, time used = 0.451s\n:::"
  },
  {
    "objectID": "geo_env/lib/python3.10/site-packages/libpysal/cg/tests/fast_point_in_polygon_algorithm.html#algorithm-for-building-quadtree-cells-for-study-area",
    "href": "geo_env/lib/python3.10/site-packages/libpysal/cg/tests/fast_point_in_polygon_algorithm.html#algorithm-for-building-quadtree-cells-for-study-area",
    "title": "Fast Point in Polygon Testing Method",
    "section": "Algorithm for building quadtree cells for study area",
    "text": "Algorithm for building quadtree cells for study area\nA huge number of points will be simulated and test if falls in the study area in the real case. This calculation process is very computing intensive. Especially when the boundary of study area is complex and contains a lot of segments, or the simulation time is also large.\nIn order to fast decide whether a point is contained in the study area, we can prepare an grid structure which divide the study area into quadtree based regular rectangles. Each rectangles will have a specific status from [‘in’, ‘out’, ‘maybe’]. After we prepared this kind of grid structure, deciding whether a points falls in the study area will be very easy: first, allocate the point into a specific cell. For the cell with different status:\n- in: the point must be in the study area\n- out: the point must not be in the study area\n- maybe: decide if the points falls into the study area by some following-up calculation. However, the small polygon contains much less boundary segments, the calculation will be much easier. What’s more, this kind of grids only take over a very small part of the whole grids\n\n\nProcess of duadtree dividing of the study area:\nTreat the boundary of the study area as arc. Each time of dividing the study area means use two straight lines (on horizontal and one vertical) to split a big rectangle (cell) into 4 smaller ones. During this process, the arc should also be used to intersect with the straight lines and break into small segments. Different segments should belong to different cells and can be used to determine the status of the cell (as we mentioned: in, out or maybe inside of the study area.) Repeat this process until the cell’s size is small enough.\nDuring the dividing, there are some special properties of the arcs we need to know:\n- Point order of the arcs MUST be clockwise\n- The two end-points of each arc MUST lie on the borders of the cell\n- When a arc goes in a cell, it MUST goes out from the same one\n- The intersection points MUST be lying on the inner-boundaries which are used to divide the cell into 4 sub-cells - Use the intersection points to split the arcs into small ones\n- No need to store cell boundaries as arcs, store the intersection points, points’ relative location from\nThe following image depicts the categorize rule of cell boundary when being divided into sub cells:\ncell_boundary_category_rule\n\nsegment_sequence_search_rule\n\nIn the situations that there are some arcs intersect with a cell and we need to extract the segment squence, here is the rule:\n1. Start on the bottom-left point of the cell, go clockwise to search points.\n2. Find the first arc-begin-point on the cell’s border. The actual segment sequence begin from here.\n3. Go alone the arc until the end point on the border. Then go alone the cell’s border until find next arc-begin-point.\n4. Repeat Step.3 until reach the first arc-begin-point at Step.2. Search stop.\nFrom the image we can see that the red border lines also belong to the segment sequence.\nDuring the quadtree dividing, when there is a cell who doesn’t intersect with any arc, we need to determine whether this cell is totally within the study area or not. we Can use the method above to determine: If this cell share a border which belongs to other cells’ segment sequence, then this cell is totally within the study area; vice versa\nextract_connecting_boders_between_points\n\nsituation_segment_intersect_with_two_split_line \nUnder the sitiation that a single segment intersects with both split-lines. This kind of situation should be carefully treated."
  },
  {
    "objectID": "geo_env/lib/python3.10/site-packages/libpysal/cg/tests/fast_point_in_polygon_algorithm.html#reference",
    "href": "geo_env/lib/python3.10/site-packages/libpysal/cg/tests/fast_point_in_polygon_algorithm.html#reference",
    "title": "Fast Point in Polygon Testing Method",
    "section": "Reference",
    "text": "Reference\nPoint in Polygon Strategies http://erich.realtimerendering.com/ptinpoly/\nSamet, Hanan. Foundations of multidimensional and metric data structures. Morgan Kaufmann, 2006.\nJiménez, Juan J., Francisco R. Feito, and Rafael J. Segura. “A new hierarchical triangle-based point-in-polygon data structure.” Computers & Geosciences 35, no. 9 (2009): 1843-1853.\nhttp://stackoverflow.com/questions/12881848/draw-polygons-more-efficiently-with-matplotlib\nhttp://matplotlib.org/api/collections_api.html\nhttp://materializecss.com/color.html"
  },
  {
    "objectID": "geo_env/lib/python3.10/site-packages/soupsieve-2.5.dist-info/licenses/LICENSE.html",
    "href": "geo_env/lib/python3.10/site-packages/soupsieve-2.5.dist-info/licenses/LICENSE.html",
    "title": "Greg Maya",
    "section": "",
    "text": "MIT License\nCopyright (c) 2018 - 2023 Isaac Muse isaacmuse@gmail.com\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  {
    "objectID": "geo_env/lib/python3.10/site-packages/pyzmq-26.0.3.dist-info/licenses/LICENSE.html",
    "href": "geo_env/lib/python3.10/site-packages/pyzmq-26.0.3.dist-info/licenses/LICENSE.html",
    "title": "Greg Maya",
    "section": "",
    "text": "BSD 3-Clause License\nCopyright (c) 2009-2012, Brian Granger, Min Ragan-Kelley\nAll rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."
  },
  {
    "objectID": "services/index_services.html",
    "href": "services/index_services.html",
    "title": "Services",
    "section": "",
    "text": "As a spatial data consultant, I mostly work with teams who want to take their data to the next level.\nMy approach is not to provide isolated solutions, but instead to walk the journey with you while making sure that the output is fit for purpose but also maintainable by you.\nMost of what I focus on:\n\nUrban diagnostics\nMorphological metrics for scenario testing\nPost-occupancy studies\nNetwork modeling for spatial and social environments\nSpatial visibility analysis\nInteractive data visualization (spatial and not!)\n\n\nTools & Softwares\nI use an array of tools depending on the needs. Yes, my preferance is usually to go open-source but this is not always possible. The following are just some tools I commonly use:\nPython, PostGIS - SQL, Tableau, QGIS, Isovists, Gephi, to name a few…\n\n\n\nWorked with:\n\n\n\n\n\n\nProp Tech\n Property technology companies are constantly trying to leverage their location information for augmented business insights. \n\n\n\n\n\n\n\n\n\n\nReal Estate Managers\n Managers need to create information pipelines to track and report space utilization for improving performance and community building. \n\n\n\n\n\n\n\n\n\n\nArchitect Studios and Urban Planners\n Planners need analytics on land use, pedestrian movement, urban morphology, and more to create sustainable designs and policies based on evidence. \n\n\n\n\n\n\n\n\n\n\nAcademia\n Network theories, morphological analysis or data analysis are not common practices for most social sciencies nowadays, but current market asks for profesionals aware of these domains. \n\n\n\n\n\n\n\n\n\n\nData Visualisation\n Most people and organisations need easy ways to represent and understand their data. I can help to create data pipelines and dashboards for revealing important information."
  },
  {
    "objectID": "work/others/articles.html",
    "href": "work/others/articles.html",
    "title": "Articles",
    "section": "",
    "text": "The following are non academic articles I have been invited to write, where I have been able to express my personal opinions. Eventhought they are part of academic environments (and their audiences are mostly academic) they are not peered-reviewed publications.\n\nExploring Salmona [ENG]\nISOVISTS.ORG, Salmona Fellowship 2019 (British Council)\nFollow link to read.\n\n\nLa configuración espacial: el valor agregado de la Arquitectura. [ESP]\nREVISTA IDEAS20, ArqDis - Uniandes\nClick to download PDF to read.",
    "crumbs": [
      "About",
      "Others",
      "Articles"
    ]
  },
  {
    "objectID": "work/urban/rab_simpl.html",
    "href": "work/urban/rab_simpl.html",
    "title": "Round About Simplification",
    "section": "",
    "text": "explaing that this was done throu",
    "crumbs": [
      "About",
      "Urban Planning",
      "Roundabout Simplification"
    ]
  },
  {
    "objectID": "work/data_viz/article19.html",
    "href": "work/data_viz/article19.html",
    "title": "Article 19",
    "section": "",
    "text": "What is Article 19?\nArticle 19 is a non-profit organisation working to protect and promote the freedom of speech in the world. Based in London but with presence in all continents, their mission is\n\n… ‘by working on two interlocking freedoms: the Freedom to Speak, and the Freedom to Know. When either of these freedoms come under threat, ARTICLE 19 speaks with one voice.’\n\n\n\nMy contributions\nInitially, I was only commissioned to analyse a small series of data points. Quickly, we realized the potential to re’think their whole pipele for their annual GxR report.\nThis is still the main focus of my work, yet, the outputs expand beyond what’s available online and now reach:\n\nPublic -general audience\n\nthrough visualisation embeds in website.\n\nInternal - A19 staff\n\nthrough data dashboards hosted in Tableau Public.\n\n\n\n\nThe Pipeline\nThe main objectives of creating a data pipeline where:\n\nto increase",
    "crumbs": [
      "About",
      "Data Visualisation",
      "Article 19"
    ]
  },
  {
    "objectID": "work/data_viz/jgraph.html",
    "href": "work/data_viz/jgraph.html",
    "title": "J-Graphs",
    "section": "",
    "text": "Justified Graphs are commonly used in Space Syntax methodology to represent the minimum number of topological steps that it requires to go from one specific point to all other points in the network.\nThis is usually an useful excercise to comnpare difference in the depth (max number of steps) of different locations of a spatial structure.\nCommonly, one looks at the depth difference between all entrances to a building and/or closeby metro stations to a plaza.\nThe main idea representede beautifly by these escercises is that ‘things looks different depending from where you are’",
    "crumbs": [
      "About",
      "Data Visualisation",
      "J-Graphs"
    ]
  },
  {
    "objectID": "work/data_viz/jgraph.html#casa-rio-frio---salmona",
    "href": "work/data_viz/jgraph.html#casa-rio-frio---salmona",
    "title": "J-Graphs",
    "section": "Casa Rio Frio - Salmona",
    "text": "Casa Rio Frio - Salmona\n\n\n\n\n\n\nNote\n\n\n\nOriginally this tool was created during my Salmona Residency program in 2019 (Sponsored by the Brithish Council).\nThe idea was to create this easy visualization tool to analise several of Salmona’s buildings. This tool was used during several workshops lead on-site, where the concept of graph analysis was introduced to local students and researchers.\n\n\n\nThe House\nLocated in a nearby rural area of Bogota (Colombia), this house was designed by Rogelio Salmona, for his personal enjoyment. In a nutshell is, it supposed to distill a lot of the design principles he develop throughout the years. In this case we tried to compare the extent to which his idea of building a house that celebrates the outdoors (in a challenging climate), could be reflcted on the overall configuation of the spaces.\n\n\n\n\n\nLayout Distribution\n\n\n\n\n\nPatio 2\n\n\n\n\nIn syntax literature, the effects of building cores -the most ‘connectected’ parts of a building- are commonly studied. According to famous theories (like the natural movement - Hiller), it is vital to understand the extent to which said core aligns with the movments of a building. In theory, the more this two are in sync, the more one can presume that the driving force for movement is due to the layout of spaces.\nYet, in this excercise all it was intended was to Visualize through individual locations, a property of ‘depth’ of the overall building. The beauty of this methos is that once can easily isolate and compare how two different spaces percieve the whole graph in relative terms from their local origin.\nHence, one need to begin to identify the units of analysis. Which in this case, I was using concave spaces (spaces where all inner points are mutually visible).\n\n\n\nConnections based on concave spaces\n\n\n\n\nCode\n# List of all connections. Future node edges\nedges = [\n    (\"M\", \"L\"),\n    (\"L\", \"K\"),\n    (\"K\", \"Q\"),\n    (\"O\", \"Q\"),\n    (\"Q\", \"P\"),\n    (\"N\", \"Q\"),\n    (\"Q\", \"C\"),\n    (\"C\", \"E\"),\n    (\"T\", \"R\"),\n    (\"S\", \"R\"),\n    (\"J\", \"B\"),\n    (\"J\", \"F\"),\n    (\"B\", \"R\"),\n    (\"B\", \"C\"),\n    (\"B\", \"A\"),\n    (\"R\", \"D\"),\n    (\"C\", \"D\"),\n    (\"C\", \"D\"),\n    (\"C\", \"F\"),\n    (\"G\", \"H\"),\n    (\"G\", \"F\"),\n    (\"F\", \"I\"),\n    (\"A\", \"X\"),\n    (\"D\", \"H\"),\n    (\"D\", \"X\"),\n    (\"H\", \"X\"),\n    (\"I\", \"X\"),\n]\n\n# Create Graph object\nG = nx.Graph()\nG.add_edges_from(edges)\n\nplt.figure(figsize=(4, 4))\nnx.draw(G, with_labels=True, node_color=\"grey\")\n\n\n\n\n\n\n\n\n\nNow, it is as easy as selecting one origin space using the jgraph_from_multiple_origins function to rapidly have a common J-Graph!\nFor example, one can look at the entrance hall (C) and compare it to the overall surroundings (in this case grouped under the label X)\n\n\nCode\njgraph_from_multiple_origins(G, \"C\")\n\n\nMean depth = 1.90\nMaximum topological steps = 4\n\n\n\n\n\n\n\n\n\n\n\nCode\njgraph_from_multiple_origins(G, \"X\")\n\n\nMean depth = 2.67\nMaximum topological steps = 6\n\n\n\n\n\n\n\n\n\nTo make things more interesting, the function was designed to accept a list of possible origins.\nThis deviates from the classical idea of a J-Graph, but it is an useful method to visualize and evaluate things like the the maximum topological depth of a builduing from all its entrances. In this case A,D and I.\n\n\nCode\nentrances = [\"A\", \"D\", \"I\"]\njgraph_from_multiple_origins(G, entrances)\n\n\nMean depth = 1.86\nMaximum topological steps = 5\n\n\n\n\n\n\n\n\n\nIn this case one sees that M is clearly the outlier. When looking at the correspondance on the floorplan, it corresponds to one of the private bathrooms (the most intimate parts of the layout), which comparatively to the entrances (the most ‘public’ parts), makes sense to be on polar opposites.\nYet, noticind how heavily loaded the steps 1,2 and 3 are one could definetly start to see the intentionality to move as many instances of the building to the entrnaces. Something that clearly aligns with the architects desire to celebrate the outdoor.\n\n\nBonus:\n\nExploring mean depth values\nEven thoough, the objective of this excercise was only about J-Graphs, I have added a small section below looking at aggregate values of mean depth in all instances of the building.\n\n\nCode\n# Define main function\ndef mean_depth_calcs(G, graph_output=True):\n    \"\"\"\n    Calculates mean depth (average shortest path length) from every node to all other nodes in the graph.\n    Optionally adds mean depth as a node attribute or returns a DataFrame with mean depths and ranks.\n\n    Parameters:\n    G (networkx.Graph): The graph on which to perform calculations.\n    graph_output (bool): If True, returns the graph with 'mean_depth' as a node attribute.\n                         If False, returns a DataFrame with mean depths and their ranks.\n\n    Returns:\n    networkx.Graph or pandas.DataFrame: Depending on the value of graph_output.\n    \"\"\"\n    nodes = list(G.nodes())\n    mean_depths = {}\n    for n in nodes:\n        # Compute shortest paths from n to all other nodes\n        path_lengths = nx.single_source_shortest_path_length(G, source=n)\n        # Calculate mean depth avoiding infinity (no path situations)\n        depths = [length for length in path_lengths.values() if length &lt; np.inf]\n        mean_depths[n] = np.mean(depths) if depths else np.inf  # Handle isolated nodes\n\n    # Set mean_depth as node attribute if required\n    if graph_output:\n        nx.set_node_attributes(G, mean_depths, \"mean_depth\")\n        return G\n    else:\n        # Create a DataFrame from the mean depths dictionary\n        df = pd.DataFrame.from_dict(mean_depths, orient=\"index\", columns=[\"mean_depth\"])\n        # Rank the mean_depths, lower is better hence ascending\n        df[\"mean_depth_rank\"] = df[\"mean_depth\"].rank(method=\"min\", ascending=True)\n        return df\n\n\nTesting the function with a graph output\n\n\nCode\n# Default function. Graph output\nmean_depth_graph = mean_depth_calcs(G)\n\n# Calculate node sizes inversely proportional to mean_depth values\nnode_mean_depths = nx.get_node_attributes(mean_depth_graph, \"mean_depth\")\nmax_depth = max(node_mean_depths.values())\n\n# Normalize and invert the sizes\nnode_sizes = {\n    node: 1000 * (1 / (depth / max_depth)) for node, depth in node_mean_depths.items()\n}\n\n# Selecting the layout\npos = nx.kamada_kawai_layout(mean_depth_graph)  # Using Kamada-Kawai layout\n\n# Draw the graph\nplt.figure(figsize=(6, 6))\nnx.draw(\n    mean_depth_graph,\n    pos,\n    node_color=list(node_mean_depths.values()),\n    node_size=[node_sizes[n] for n in mean_depth_graph.nodes()],\n    with_labels=True,\n    cmap=plt.cm.viridis,\n)\n\nplt.colorbar(\n    plt.cm.ScalarMappable(\n        cmap=plt.cm.viridis,\n        norm=plt.Normalize(\n            vmin=min(node_mean_depths.values()), vmax=max(node_mean_depths.values())\n        ),\n    ),\n    ax=plt.gca(),\n    label=\"Mean Depth\",\n)\nplt.show()\n\n\n\n\n\n\n\n\n\nTesting function with a DataFrame output\n\n\nCode\n# Testing function with a DataFrame output\nmean_depth_df = mean_depth_calcs(G, graph_output=False)\n\n# Print and display ordered DF\nprint(\"Top 5 'shallow' nodes:\")\nmean_depth_df.sort_values(\"mean_depth\", ascending=True).head()\n\n\nTop 5 'shallow' nodes:\n\n\n\n\n\n\n\n\n\nmean_depth\nmean_depth_rank\n\n\n\n\nC\n1.904762\n1.0\n\n\nD\n2.190476\n2.0\n\n\nQ\n2.238095\n3.0\n\n\nB\n2.285714\n4.0\n\n\nF\n2.428571\n5.0\n\n\n\n\n\n\n\n\n\nDistribution of mean depth values\n\n\nCode\nmean_depth_values = mean_depth_df[\"mean_depth\"]\n\n# Normalize the data for color mapping\nnorm = mcolors.Normalize(vmin=min(mean_depth_values), vmax=max(mean_depth_values))\ncmap = plt.cm.viridis  # or any other colormap\n\n# Create the histogram\nfig, ax = plt.subplots()\nn, bins, patches = ax.hist(mean_depth_values, bins=20, edgecolor=\"white\")\n\n# Calculate the bin centers\nbin_centers = 0.5 * (bins[:-1] + bins[1:])\n\n# Color each bin according to the mean_depth value it represents\nfor bin_center, patch in zip(bin_centers, patches):\n    # Calculate color for the bin based on bin center\n    bin_color = cmap(norm(bin_center))\n    patch.set_facecolor(bin_color)\n\n# Add a colorbar to show the mapping from color to the mean_depth values\nsm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\nsm.set_array([])\ncbar = fig.colorbar(sm, ax=ax, label=\"Mean Depth\")\n\n# Plotting details\nax.set_title(\"Histogram of Mean Depths\")\nax.set_xlabel(\"Mean Depth\")\nax.set_ylabel(\"Frequency\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\nsummary_series = mean_depth_df.mean_depth.describe()\n\n# Convert the Series to a DataFrame, with index reset as a new column\nmean_depth_df_formatted = summary_series.reset_index()\n\n# Rename the columns for better readability\nmean_depth_df_formatted.columns = [\"Statistic\", \"Mean Depth\"]\n# Round the values to two decimal places\nmean_depth_df_formatted[\"Mean Depth\"] = mean_depth_df_formatted[\"Mean Depth\"].round(2)\n\nmean_depth_df_formatted\n\n\n\n\n\n\n\n\n\nStatistic\nMean Depth\n\n\n\n\n0\ncount\n21.00\n\n\n1\nmean\n2.93\n\n\n2\nstd\n0.62\n\n\n3\nmin\n1.90\n\n\n4\n25%\n2.67\n\n\n5\n50%\n2.86\n\n\n6\n75%\n3.14\n\n\n7\nmax\n4.67\n\n\n\n\n\n\n\nTo see more about this project and the overall residency see Exploring Salmona under Other / Articles section.",
    "crumbs": [
      "About",
      "Data Visualisation",
      "J-Graphs"
    ]
  }
]